{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5bfe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a07dbda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _psi(expected: np.ndarray, actual: np.ndarray, bucket_type: str = \"bins\", n_bins: int = 10) -> float:\n",
    "    \"\"\"Calculate PSI metric for two arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        expected : list-like\n",
    "            Array of expected values\n",
    "        actual : list-like\n",
    "            Array of actual values\n",
    "        bucket_type : str\n",
    "            Binning strategy. Accepts two options: 'bins' and 'quantiles'. Defaults to 'bins'.\n",
    "            'bins': input arrays are splitted into bins with equal\n",
    "                and fixed steps based on 'expected' array\n",
    "            'quantiles': input arrays are binned according to 'expected' array\n",
    "                with given number of n_bins\n",
    "        n_bins : int\n",
    "            Number of buckets for binning. Defaults to 10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A single float number\n",
    "    \"\"\"\n",
    "    breakpoints = np.arange(0, n_bins + 1) / (n_bins) * 100\n",
    "    if bucket_type == \"bins\":\n",
    "        breakpoints = np.histogram(expected, n_bins)[1]\n",
    "    elif bucket_type == \"quantiles\":\n",
    "        breakpoints = np.percentile(expected, breakpoints)\n",
    "\n",
    "    # Calculate frequencies\n",
    "    expected_percents = np.histogram(expected, breakpoints)[0] / len(expected)\n",
    "    actual_percents = np.histogram(actual, breakpoints)[0] / len(actual)\n",
    "    # Clip freaquencies to avoid zero division\n",
    "    expected_percents = np.clip(expected_percents, a_min=0.0001, a_max=None)\n",
    "    actual_percents = np.clip(actual_percents, a_min=0.0001, a_max=None)\n",
    "    # Calculate PSI\n",
    "    psi_value = (expected_percents - actual_percents) * np.log(expected_percents / actual_percents)\n",
    "    psi_value = sum(psi_value)\n",
    "\n",
    "    return psi_value\n",
    "\n",
    "\n",
    "def calculate_psi(\n",
    "        expected: np.ndarray, actual: np.ndarray, bucket_type: str = \"bins\", n_bins: int = 10, axis: int = 0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Apply PSI calculation to 2 1-d or 2-d arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expected : list-like\n",
    "        Array of expected values\n",
    "    actual : list-like\n",
    "        Array of actual values\n",
    "    bucket_type : str\n",
    "        Binning strategy. Accepts two options: 'bins' and 'quantiles'. Defaults to 'bins'.\n",
    "            'bins' - input arrays are splitted into bins with equal\n",
    "                and fixed steps based on ’expected' array\n",
    "            'quantiles' - input arrays are binned according to ’expected’ array\n",
    "                with given number of n_bins\n",
    "    n_bins : int\n",
    "        Number of buckets for binning. Defaults to 10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        np.ndarray\n",
    "    \"\"\"\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        if len(psi_values) == 1:\n",
    "            psi_values = _psi(expected, actual, bucket_type, n_bins)\n",
    "        elif axis == 0:\n",
    "            psi_values[i] = _psi(expected[:, i], actual[:, i], bucket_type, n_bins)\n",
    "        elif axis == 1:\n",
    "            psi_values[i] = _psi(expected[i, :], actual[i, :], bucket_type, n_bins)\n",
    "        return np.array(psi_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc3dfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('googl_daily_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750aadd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>171.350</td>\n",
       "      <td>172.2050</td>\n",
       "      <td>167.4400</td>\n",
       "      <td>171.74</td>\n",
       "      <td>50912792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>174.000</td>\n",
       "      <td>174.4193</td>\n",
       "      <td>170.6300</td>\n",
       "      <td>171.86</td>\n",
       "      <td>29373803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>173.160</td>\n",
       "      <td>175.2650</td>\n",
       "      <td>171.9107</td>\n",
       "      <td>172.36</td>\n",
       "      <td>34783997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>170.160</td>\n",
       "      <td>173.1700</td>\n",
       "      <td>170.0000</td>\n",
       "      <td>172.90</td>\n",
       "      <td>37995670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>169.055</td>\n",
       "      <td>169.9600</td>\n",
       "      <td>167.8900</td>\n",
       "      <td>168.47</td>\n",
       "      <td>35211439.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  1. open   2. high    3. low  4. close   5. volume\n",
       "0  2025-05-30  171.350  172.2050  167.4400    171.74  50912792.0\n",
       "1  2025-05-29  174.000  174.4193  170.6300    171.86  29373803.0\n",
       "2  2025-05-28  173.160  175.2650  171.9107    172.36  34783997.0\n",
       "3  2025-05-27  170.160  173.1700  170.0000    172.90  37995670.0\n",
       "4  2025-05-23  169.055  169.9600  167.8900    168.47  35211439.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db18057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "df['year'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6971f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expected = df[df['year']==2024]['5. volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be17999d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.520000e+02\n",
       "mean     2.744196e+07\n",
       "std      1.129977e+07\n",
       "min      1.024213e+07\n",
       "25%      2.048537e+07\n",
       "50%      2.403958e+07\n",
       "75%      3.136293e+07\n",
       "max      7.191004e+07\n",
       "Name: 5. volume, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expected.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3d3eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual = df[df['year']==2023]['5. volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "145e7a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.500000e+02\n",
       "mean     3.272150e+07\n",
       "std      1.321764e+07\n",
       "min      1.251432e+07\n",
       "25%      2.508057e+07\n",
       "50%      2.925293e+07\n",
       "75%      3.623504e+07\n",
       "max      1.194550e+08\n",
       "Name: 5. volume, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2b44b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.46948006)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_psi(df_expected, df_actual, bucket_type=\"bins\", n_bins=10, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862151d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
